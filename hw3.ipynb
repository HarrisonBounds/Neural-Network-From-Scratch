{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSAI349: Homework 3\n",
    "Authors: Sayantani Bhattacharya, Harrison Bounds, Andrew Kwolek, Sharwin Patil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Block\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.optim import Optimizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import Callable, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Code\n",
    "Plotting code provided in starter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "################################################################################\n",
    "# Some simple plotting utilities\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def plot_data(data: np.ndarray,\n",
    "              labels: np.ndarray,\n",
    "              ax: matplotlib.axes.Axes = None):\n",
    "    \"\"\"\n",
    "    A helper function to plot our data sets\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    data      A numpy array of 2 columns (dimensions) and 2*examples_per_class rows\n",
    "\n",
    "    labels    A numpy vector with 2*examples_per_class, with a +1 or -1 in each\n",
    "              element. The jth element is the label of the jth example\n",
    "\n",
    "    ax        An optional matplotlib axis object to plot to\n",
    "    \"\"\"\n",
    "\n",
    "    # require shape (n, 2)\n",
    "    assert data.ndim == 2\n",
    "    assert data.shape[-1] == 2\n",
    "\n",
    "    if type(data) == torch.Tensor:\n",
    "        data = data.numpy()\n",
    "\n",
    "    # plot the data\n",
    "    pos_idx = np.where(labels == 1)\n",
    "    neg_idx = np.where(labels == -1)\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt\n",
    "    ax.plot(\n",
    "        data.T[0, pos_idx],\n",
    "        data.T[1, pos_idx],\n",
    "        'r^',\n",
    "        label='positive'\n",
    "    )\n",
    "    ax.plot(\n",
    "        data.T[0, neg_idx],\n",
    "        data.T[1, neg_idx],\n",
    "        'bo',\n",
    "        label='negative'\n",
    "    )\n",
    "    ax.axis('equal')\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(), loc=\"upper right\")\n",
    "\n",
    "    if ax is None:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_decision_surface(model=None,\n",
    "                          axis_limits=(-5, 5, -5, 5),\n",
    "                          ax: matplotlib.axes.Axes = None\n",
    "                          ):\n",
    "    \"\"\"\n",
    "    Creates a grid of points, measures what a model would label each\n",
    "    point as, and uses this data to draw a region for class +1 and a region for\n",
    "    class -1.\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model       A callable model that can take 2-d real-valued input and produce\n",
    "                a +1 or -1 label for each data point.\n",
    "\n",
    "    axis_limits An array-like object with 4 floats [lowest_horizontal, highest_horizontal,\n",
    "                lowest_vertical, highest_vertical]. This sets the limits over which\n",
    "                the decision surface will be caluclated and plotted.\n",
    "\n",
    "    ax          An optional matplotlib axis object to plot to\n",
    "\n",
    "    RETURNS\n",
    "    -------\n",
    "    my_contour  a matplotlib.contour.QuadContourSet with the contour\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a grid of points spanning the entire space displayed in the axis.\n",
    "    # This will let us draw the decision boundary later\n",
    "    xx, yy = np.meshgrid(np.arange(axis_limits[0], axis_limits[1], .05),\n",
    "                         np.arange(axis_limits[2], axis_limits[3], .05))\n",
    "    data = np.concatenate([xx.reshape([1, -1]), yy.reshape([1, -1])]).T\n",
    "\n",
    "    # Predict the class of each point in XGrid, using the classifier.\n",
    "    # This shows our regions determined by the classifier\n",
    "    if isinstance(model, nn.Module):\n",
    "        with torch.no_grad():\n",
    "            pl = model(torch.tensor(data).to(dtype=torch.float32))\n",
    "            predicted_labels = np.sign(pl.numpy())\n",
    "    else:\n",
    "        predicted_labels = model(data)\n",
    "\n",
    "    predicted_labels = predicted_labels.reshape(xx.shape)\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    if ax is None:\n",
    "        ax = plt\n",
    "\n",
    "    ax.contourf(xx, yy, predicted_labels, cmap=plt.cm.Paired)\n",
    "    ax.axis('equal')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    if ax is None:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def compute_bounds(features):\n",
    "    min1, max1 = features[:, 0].min()-1, features[:, 0].max()+1\n",
    "    min2, max2 = features[:, 1].min()-1, features[:, 1].max()+1\n",
    "    return (min1, max1, min2, max2)\n",
    "\n",
    "\n",
    "def plot_decision_regions(\n",
    "        features, targets, model,\n",
    "        axis=None, transform=None,\n",
    "        bounds=None,\n",
    "        title='Decision Surface'):\n",
    "    \"\"\"\n",
    "    Slightly different plotting approach than above. Used in backprop demo.\n",
    "\n",
    "    This function produces a single plot containing a scatter plot of the\n",
    "    features, targets, and decision region of the model.\n",
    "\n",
    "    Args:\n",
    "        features (np.ndarray): 2D array containing real-valued inputs.\n",
    "        targets (np.ndarray): 1D array containing binary targets.\n",
    "        model: a learner with .predict() method\n",
    "        axis: the axis on which to plot. If None, create a new plot\n",
    "        title: title of the plot\n",
    "    Returns:\n",
    "        None (plots to the active figure)\n",
    "    \"\"\"\n",
    "\n",
    "    # define bounds of the domain\n",
    "    if bounds is None:\n",
    "        min1, max1, min2, max2 = compute_bounds(features)\n",
    "    else:\n",
    "        min1, max1, min2, max2 = bounds\n",
    "\n",
    "    # define grid for visualizing decision regions\n",
    "    x1grid = np.arange(min1, max1, 0.1)\n",
    "    x2grid = np.arange(min2, max2, 0.1)\n",
    "\n",
    "    xx, yy = np.meshgrid(x1grid, x2grid)\n",
    "\n",
    "    # flatten grid to a vector\n",
    "    r1, r2 = xx.flatten(), yy.flatten()\n",
    "    r1, r2 = r1.reshape((len(r1), 1)), r2.reshape((len(r2), 1))\n",
    "\n",
    "    # horizontally stack vectors to create x1,x2 input for the model\n",
    "    grid = np.hstack((r1, r2))\n",
    "\n",
    "    # if we're transforming the features, do that now\n",
    "    #     this allows xx and yy to still be in 2D for the visualization\n",
    "    #     but grid has been transformed so it matches up with the fit model\n",
    "    if transform is not None:\n",
    "        grid = transform(grid)\n",
    "\n",
    "    # generate predictions over grid\n",
    "    yhat = model.predict(grid)\n",
    "\n",
    "    # reshape the predictions back into a grid\n",
    "    zz = yhat.reshape(xx.shape)\n",
    "\n",
    "    if axis is None:\n",
    "        fig, axis = plt.subplots()\n",
    "\n",
    "    # plot the grid of x, y and z values as a surface\n",
    "    binary_cmap = matplotlib.colors.ListedColormap(['#9ce8ff', '#ffc773'])\n",
    "    axis.contourf(xx, yy, zz, cmap=binary_cmap, alpha=0.7)\n",
    "\n",
    "    # plot \"negative\" class:\n",
    "    row_idx_neg = np.where(targets < 0.5)[0]\n",
    "    axis.scatter(\n",
    "        features[row_idx_neg, 0], features[row_idx_neg, 1],\n",
    "        label='negative')\n",
    "\n",
    "    # plot \"positive\" class:\n",
    "    row_idx_pos = np.where(targets > 0.5)[0]\n",
    "    axis.scatter(\n",
    "        features[row_idx_pos, 0], features[row_idx_pos, 1],\n",
    "        label='positive')\n",
    "\n",
    "    axis.set_title(title)\n",
    "    axis.set_xlim(min1, max1)\n",
    "    axis.set_ylim(min2, max2)\n",
    "\n",
    "    axis.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 & 2\n",
    "PyTorch Implementaion with MCE and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \"\"\"Binary Classification in pytorch using either multi-class cross entropy or mean squared error loss functions\"\"\"\n",
    "    def __init__(self, input_size: int, hl_size: int, output_size: int, regularizer: str = None):\n",
    "        \"\"\"Initialize the network with the size of each layer\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of features in the dataset\n",
    "            hl_size (int): hidden layer size\n",
    "            output_size (int): output size (1 for MSE loss, 2 for MCE loss)\n",
    "            regularizer (str, optional): Regularization term [norm, orthogonal]. Defaults to None.\n",
    "        \"\"\"\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hl_size)\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(hl_size, output_size)\n",
    "        if output_size == 2:\n",
    "            self.output = nn.Softmax()\n",
    "        elif output_size == 1:\n",
    "            self.output = nn.Sigmoid()\n",
    "        self.regularizer = regularizer\n",
    "        self.regularizer_lambda = 0.01\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using {self.device} for training\")\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Forward pass for the neural network\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input data in the form of a tensor\n",
    "\n",
    "        Returns:\n",
    "            Tensor: data after the nework has processed it (output tensor)\n",
    "        \"\"\"\n",
    "        x = self.linear1(x)\n",
    "        x = self.sigmoid1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "    def train_model(self, model: nn.Module, num_epochs: int, X_train: Tensor, y_train: Tensor, X_valid: Tensor, y_valid: Tensor, loss_func: Callable, optimizer: Optimizer) -> list:\n",
    "        \"\"\"Use Stochastic Gradient Descent to train one example at a time\n",
    "\n",
    "        Args:\n",
    "            model (nn.Module): Model created by the forward pass\n",
    "            num_epochs (int): Number of times to train the entire dataset\n",
    "            X_train (Tensor): Training data without labels\n",
    "            y_train (Tensor): Labels for the training data\n",
    "            X_valid (Tensor): Validation data without labels\n",
    "            y_valid (Tensor): Labels for the validation data\n",
    "            loss_func (Callable): callable function to perform the loss calculation on the output\n",
    "            optimizer (Optimizer): Built in optimzer to perform momentum based learning\n",
    "        \"\"\"\n",
    "        training_learning_curve = []\n",
    "        validation_learning_curve = []\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            training_loss = 0\n",
    "            for i in range(len(X_train)):\n",
    "\n",
    "                x = X_train[i]\n",
    "                y = y_train[i]\n",
    "\n",
    "                y_pred = model(x)\n",
    "                loss = loss_func(y_pred, y)\n",
    "\n",
    "                if self.regularizer == \"norm\":\n",
    "                    input_layer_weights = model.linear1.weight\n",
    "                    regularizer_value = torch.sum(input_layer_weights ** 2)\n",
    "                    loss += self.regularizer_lambda * regularizer_value\n",
    "                elif self.regularizer == \"orthogonal\":\n",
    "                    # encourage orthogonality in the intermediate decision\n",
    "                    # boundaries learned in the first layer\n",
    "                    input_layer_weights = model.linear1.weight\n",
    "                    dot_products = torch.mm(\n",
    "                        input_layer_weights, input_layer_weights.t()\n",
    "                    )\n",
    "                    identity = torch.eye(dot_products.shape[0])\n",
    "                    orthogonality_loss = torch.sum(\n",
    "                        (dot_products - identity) ** 2)\n",
    "                    loss += self.regularizer_lambda * orthogonality_loss\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Accumulate loss for the epoch\n",
    "                training_loss += loss.item()\n",
    "            # Learning curve should be average loss per epoch\n",
    "            training_learning_curve.append(training_loss / len(X_train))\n",
    "            # Validation Phase\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                validation_loss = 0\n",
    "                for i in range(len(X_valid)):\n",
    "                    x_valid = X_valid[i]\n",
    "                    y_val = y_valid[i]\n",
    "\n",
    "                    y_valid_pred = model(x_valid)\n",
    "                    loss = loss_func(y_valid_pred, y_val)\n",
    "                    validation_loss += loss.item()\n",
    "                # Learning curve should be average loss per epoch\n",
    "                validation_learning_curve.append(\n",
    "                    validation_loss / len(X_valid))\n",
    "\n",
    "        return training_learning_curve, validation_learning_curve\n",
    "\n",
    "    def predict(self, X: Tensor) -> Tensor:\n",
    "        \"\"\"Predict the output of the network\n",
    "\n",
    "        Args:\n",
    "            X (Tensor): Input data without labels\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Predicted output of the network\n",
    "        \"\"\"\n",
    "        model = self\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            return model(X)\n",
    "\n",
    "    def validate_test(self, model: nn.Module, X_test: Tensor, y_test: Tensor, loss_func_label: str) -> float:\n",
    "        \"\"\"Test the validation and test set accuracies by divinding the correct predictions by the total predicitions\n",
    "\n",
    "        Args:\n",
    "            model (nn.Module): Model created by the forward pass\n",
    "            X_test (Tensor): Testing/Validation data without labels\n",
    "            y_test (Tensor): Labels for the testing/validation data\n",
    "            loss_func_label (str): Specifies either MSE or MCE loss\n",
    "\n",
    "        Returns:\n",
    "            float: accuracy evaluation metric to see how well the network is performing\n",
    "        \"\"\"\n",
    "        model.eval()  # Set the model to 'evaluation' mode\n",
    "        # Disable gradient calculation for testing\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for i in range(len(X_test)):\n",
    "                x = X_test[i]\n",
    "                y = y_test[i]\n",
    "\n",
    "                if loss_func_label == \"MCE\":\n",
    "                    # Second probability in output: (Second probability so we can keep the logic the same for clipping)\n",
    "                    pred = model(x)[1]\n",
    "                elif loss_func_label == \"MSE\":\n",
    "                    pred = model(x)\n",
    "\n",
    "                # Clipping: If the second element has higher than a 50% probability, then it is of class 1, otherwise class 0\n",
    "                pred = 1 if pred >= 0.5 else 0\n",
    "\n",
    "                if pred == y:\n",
    "                    correct += 1\n",
    "\n",
    "                total += 1\n",
    "\n",
    "        accuracy = correct / total\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "class HyperParams:\n",
    "    def __init__(self, hidden_layer_size: int, learning_rate: float, loss_func: str):\n",
    "        self._hl_size = hidden_layer_size\n",
    "        self._lr = learning_rate\n",
    "        self._output_size = 2 if loss_func == \"MCE\" else 1\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.hl_size, self.lr, self.output_size))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"[HLSize: {self.hl_size}, LR: {self.lr}, Loss: {'MCE' if self.output_size == 2 else 'MSE'}]\"\n",
    "\n",
    "    @property\n",
    "    def hl_size(self):\n",
    "        return self._hl_size\n",
    "\n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self._lr\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._output_size\n",
    "\n",
    "\n",
    "class NeuralNetEvaluator:\n",
    "    def __init__(\n",
    "            self,\n",
    "            training_data: dict[str: str],\n",
    "            test_data: dict[str: str],\n",
    "            validation_data: dict[str: str],\n",
    "            loss_functions: dict[str: Callable]):\n",
    "        self.training_data = training_data\n",
    "        self.test_data = test_data\n",
    "        self.validation_data = validation_data\n",
    "        self.loss_functions = loss_functions\n",
    "        self.used_regularizer = \"\"\n",
    "\n",
    "        # Store the evaluated models as a dictionary that maps\n",
    "        # a tuple of the dataset name and the hyperparams to a\n",
    "        # dictionary of accuracy_names to accuracy values\n",
    "        # Example Entry: (\"dataset_name\", HyperParams): {\"valid_accuracy\": 0.5, \"test_accuracy\": 0.6}\n",
    "        self.evaluated_models: dict[\n",
    "            Tuple[str, HyperParams]: dict[str: float]\n",
    "        ] = {}\n",
    "        # Store the best models as a map of\n",
    "        # dataset_name_loss to the model itself\n",
    "        self.all_models: dict[str: dict[HyperParams: NeuralNet]] = {}\n",
    "        self.best_models: dict[str: NeuralNet] = {}\n",
    "\n",
    "    def train_model(\n",
    "            self,\n",
    "            dataset_name: str,\n",
    "            loss_func_name: str,\n",
    "            regularizer: str,\n",
    "            hyperparams: HyperParams):\n",
    "        # Assign hyperparams to default if not provided\n",
    "        # Convert data to tensors\n",
    "        X_train = pd.read_csv(self.training_data[dataset_name])\n",
    "        X_test = pd.read_csv(self.test_data[dataset_name])\n",
    "        X_validation = pd.read_csv(self.validation_data[dataset_name])\n",
    "        # Seperate labels\n",
    "        y_train = X_train[\"label\"].values\n",
    "        y_test = X_test[\"label\"].values\n",
    "        y_validation = X_validation[\"label\"].values\n",
    "        # Drop labels\n",
    "        X_train = X_train.drop(\"label\", axis=1).values\n",
    "        X_test = X_test.drop(\"label\", axis=1).values\n",
    "        X_validation = X_validation.drop(\"label\", axis=1).values\n",
    "        # Convert to tensors for numpy to use\n",
    "        X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "        X_validation = torch.tensor(X_validation, dtype=torch.float32)\n",
    "        # For MCE, we need to convert the labels to long\n",
    "        if loss_func_name == \"MCE\":\n",
    "            y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "            y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "            y_validation = torch.tensor(y_validation, dtype=torch.long)\n",
    "        elif loss_func_name == \"MSE\":\n",
    "            y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "            y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "            y_validation = torch.tensor(y_validation, dtype=torch.float32)\n",
    "        # Build network with loss function and optimizer\n",
    "        if regularizer is not None or regularizer != \"\":\n",
    "            self.used_regularizer = regularizer\n",
    "        neural_network = NeuralNet(\n",
    "            X_train.shape[1],\n",
    "            hl_size=hyperparams.hl_size,\n",
    "            output_size=2 if loss_func_name == \"MCE\" else 1,\n",
    "            regularizer=regularizer if regularizer != \"\" else None\n",
    "        )\n",
    "        loss_func = self.loss_functions[loss_func_name]\n",
    "        optimizer = torch.optim.Adam(\n",
    "            neural_network.parameters(),\n",
    "            lr=hyperparams.lr\n",
    "        )\n",
    "        # Train the model\n",
    "        training_losses, validation_losses = neural_network.train_model(\n",
    "            neural_network,\n",
    "            num_epochs=500,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_valid=X_validation,\n",
    "            y_valid=y_validation,\n",
    "            loss_func=loss_func,\n",
    "            optimizer=optimizer\n",
    "        )\n",
    "        # Evaluate the model\n",
    "        valid_accuracy = neural_network.validate_test(\n",
    "            neural_network,\n",
    "            X_validation,\n",
    "            y_validation,\n",
    "            loss_func_name\n",
    "        )\n",
    "        test_accuracy = neural_network.validate_test(\n",
    "            neural_network,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            loss_func_name\n",
    "        )\n",
    "        # Save the accuracy to the evaluated models\n",
    "        key = (dataset_name, hyperparams)\n",
    "        self.evaluated_models[key] = {\n",
    "            \"valid_accuracy\": valid_accuracy,\n",
    "            \"test_accuracy\": test_accuracy,\n",
    "            \"training_losses\": training_losses,\n",
    "            \"validation_losses\": validation_losses\n",
    "        }\n",
    "        dataset_loss = f\"{dataset_name}_{loss_func_name}\"\n",
    "        if dataset_loss not in self.all_models:\n",
    "            self.all_models[dataset_loss] = {}\n",
    "        self.all_models[dataset_loss][hyperparams] = neural_network\n",
    "        print(\n",
    "            f\"Finished training {dataset_name} with Hyperparams: {hyperparams}\" +\n",
    "            f\" with loss function: {\n",
    "                loss_func_name} and regularizer: {\"None\" if regularizer == \"\" else regularizer}\"\n",
    "        )\n",
    "\n",
    "    def print_evaluated_models(self):\n",
    "        unique_datasets = set([key[0] for key in self.evaluated_models.keys()])\n",
    "        print(\n",
    "            f'Evaluated {len(self.evaluated_models)} models over ' +\n",
    "            f'{len(unique_datasets)} datasets'\n",
    "        )\n",
    "        for key in self.evaluated_models.keys():\n",
    "            dataset_name, hyper_params = key\n",
    "            valid_accuracy = self.evaluated_models[key][\"valid_accuracy\"]\n",
    "            test_accuracy = self.evaluated_models[key][\"test_accuracy\"]\n",
    "            print(\"======================================\")\n",
    "            print(f\"{dataset_name} with Hyperparams: {hyper_params}\")\n",
    "            print(f\"Validation Accuracy: {valid_accuracy}\")\n",
    "            print(f\"Test Accuracy: {test_accuracy}\")\n",
    "            print(\"======================================\\n\")\n",
    "\n",
    "    def find_best_hyperparams_for_dataset(self, dataset_name: str, loss_func_name: str):\n",
    "        # This assumes that the models are already trained and stored\n",
    "        best_test_accuracy = 0\n",
    "        best_valid_accuracy = 0\n",
    "        best_hyperparams = None\n",
    "        # dataset_models should be all the models where the dataset_name is the key\n",
    "        loss_output_size = 2 if loss_func_name == \"MCE\" else 1\n",
    "        dataset_models = [\n",
    "            key for key in self.evaluated_models.keys() if key[0] == dataset_name and key[1].output_size == loss_output_size\n",
    "        ]\n",
    "        for key in dataset_models:\n",
    "            dataset, hp = key\n",
    "            valid_accuracy = self.evaluated_models[key][\"valid_accuracy\"]\n",
    "            test_accuracy = self.evaluated_models[key][\"test_accuracy\"]\n",
    "            if valid_accuracy > best_valid_accuracy:\n",
    "                best_test_accuracy = test_accuracy\n",
    "                best_valid_accuracy = valid_accuracy\n",
    "                best_hyperparams = hp\n",
    "        dataset_loss = f\"{dataset_name}_{loss_func_name}\"\n",
    "        model_dict = self.all_models[dataset_loss]\n",
    "        # Find the entry that matches the best hyperparams\n",
    "        best_model = model_dict[best_hyperparams]\n",
    "        self.best_models[dataset_loss] = best_model\n",
    "        return best_hyperparams, best_valid_accuracy, best_test_accuracy\n",
    "\n",
    "    def plot_learning_curves(self, dataset_name: str, best_hp: HyperParams):\n",
    "        # Plot the learning curve for training and validation loss as\n",
    "        # a function of training epochs\n",
    "        # find the epoch_losses for the best hyperparams\n",
    "        key = (dataset_name, best_hp)\n",
    "        loss = \"MCE\" if best_hp.output_size == 2 else \"MSE\"\n",
    "        training_losses = self.evaluated_models[key][\"training_losses\"]\n",
    "        validation_losses = self.evaluated_models[key][\"validation_losses\"]\n",
    "        plt.figure()\n",
    "        if self.used_regularizer is not None or self.used_regularizer != \"\":\n",
    "            reg_tag = f\"_{self.used_regularizer}\"\n",
    "        plt.plot(\n",
    "            range(len(training_losses)), training_losses,\n",
    "            label=f\"{dataset_name}_{loss}_{\n",
    "                best_hp.hl_size}{reg_tag}_training_loss\"\n",
    "        )\n",
    "        plt.plot(\n",
    "            range(len(validation_losses)), validation_losses,\n",
    "            label=f\"{dataset_name}_{loss}_{\n",
    "                best_hp.hl_size}{reg_tag}_validation_loss\"\n",
    "        )\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\n",
    "            f\"{dataset_name} (k={best_hp.hl_size}, \" +\n",
    "            f\"reg={'None' if self.used_regularizer == '' else self.used_regularizer}\" +\n",
    "            f\", loss={loss}) Learning Curve\"\n",
    "        )\n",
    "        plt.legend([\"Training Loss\", \"Validation Loss\"])\n",
    "        plt.savefig(\n",
    "            f\"plots/{dataset_name}_{best_hp.hl_size}_{\n",
    "                loss}{reg_tag}_learning_curve.png\"\n",
    "        )\n",
    "\n",
    "    def plot_learned_decision_surfaces(self, dataset_name: str, loss_func_name: str):\n",
    "        # Plot the learned decision surface along with observations from the test set\n",
    "        dataset_loss = f\"{dataset_name}_{loss_func_name}\"\n",
    "        # plot_decision_surface(model=self.best_models[dataset_loss])\n",
    "        X_test = pd.read_csv(self.test_data[dataset_name])\n",
    "        y_test = X_test[\"label\"].values\n",
    "        plot_decision_regions(\n",
    "            features=X_test.drop(\"label\", axis=1).values,\n",
    "            targets=y_test,\n",
    "            model=self.best_models[dataset_loss]\n",
    "        )\n",
    "\n",
    "\n",
    "def evaluate_models_on_all_datasets():\n",
    "    print(f\"WARNING: This script will take a long time to run ...\")\n",
    "    evaluator = NeuralNetEvaluator(\n",
    "        training_data={\"xor\": \"xor_train.csv\",\n",
    "                       \"center_surround\": \"center_surround_train.csv\",\n",
    "                       \"spiral\": \"spiral_train.csv\",\n",
    "                       \"two_gaussians\": \"two_gaussians_train.csv\"\n",
    "                       },\n",
    "        test_data={\"xor\": \"xor_test.csv\",\n",
    "                   \"center_surround\": \"center_surround_test.csv\",\n",
    "                   \"spiral\": \"spiral_test.csv\",\n",
    "                   \"two_gaussians\": \"two_gaussians_test.csv\"\n",
    "                   },\n",
    "        validation_data={\"xor\": \"xor_valid.csv\",\n",
    "                         \"center_surround\": \"center_surround_valid.csv\",\n",
    "                         \"spiral\": \"spiral_valid.csv\",\n",
    "                         \"two_gaussians\": \"two_gaussians_valid.csv\"\n",
    "                         },\n",
    "        loss_functions={\"MCE\": nn.CrossEntropyLoss(), \"MSE\": nn.MSELoss()}\n",
    "    )\n",
    "    datasets = [\"xor\", \"center_surround\", \"spiral\", \"two_gaussians\"]\n",
    "    hidden_layer_sizes = [2, 3, 5, 7, 9]\n",
    "    losses = [\"MCE\", \"MSE\"]\n",
    "    # After running and manually inspecting the results,\n",
    "    # these are the best HPs for each dataset and loss function\n",
    "    # These should also be used when using regularizers\n",
    "    best_hps_map = {\n",
    "        \"xor_MCE\": HyperParams(7, 0.01, \"MCE\"),\n",
    "        \"xor_MSE\": HyperParams(9, 0.01, \"MSE\"),\n",
    "        \"center_surround_MCE\": HyperParams(3, 0.01, \"MCE\"),\n",
    "        \"center_surround_MSE\": HyperParams(3, 0.01, \"MSE\"),\n",
    "        \"spiral_MCE\": HyperParams(9, 0.01, \"MCE\"),\n",
    "        \"spiral_MSE\": HyperParams(9, 0.01, \"MSE\"),\n",
    "        \"two_gaussians_MCE\": HyperParams(2, 0.01, \"MCE\"),\n",
    "        \"two_gaussians_MSE\": HyperParams(3, 0.01, \"MSE\")\n",
    "    }\n",
    "    for dataset in tqdm(datasets, desc=\"Datasets\"):\n",
    "        for loss in losses:\n",
    "            dataset_loss = f\"{dataset}_{loss}\"\n",
    "            hp = best_hps_map[dataset_loss]\n",
    "            evaluator.train_model(dataset, loss, \"\", hp)\n",
    "    # Uncomment this block to train models with different hyperparams\n",
    "    # for dataset in tqdm(datasets, desc=\"Datasets\"):\n",
    "    #     for hl_size in hidden_layer_sizes:\n",
    "    #         for loss in losses:\n",
    "    #             hp = HyperParams(hl_size, 0.01, loss)\n",
    "    #             evaluator.train_model(dataset, loss, hp)\n",
    "    evaluator.print_evaluated_models()\n",
    "    for dataset in datasets:\n",
    "        for loss_name in losses:\n",
    "            best_hp, valid_acc, test_acc = evaluator.find_best_hyperparams_for_dataset(\n",
    "                dataset, loss_name\n",
    "            )\n",
    "            print(\"======================================\")\n",
    "            print(f\"Best Hyperparams for {dataset}: {best_hp}\")\n",
    "            print(f\"Validation Accuracy: {valid_acc}\")\n",
    "            print(f\"Test Accuracy: {test_acc}\")\n",
    "            print(\"======================================\\n\")\n",
    "            evaluator.plot_learning_curves(dataset, best_hp)\n",
    "            # evaluator.plot_learned_decision_surfaces(dataset, loss_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the evaluation\n",
    "evaluate_models_on_all_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Manual Gradients and Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Regularizers\n",
    "Repeat parts 1 and 2 with regularizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_on_all_datasets():\n",
    "    print(f\"WARNING: This script will take a long time to run ...\")\n",
    "    evaluator = NeuralNetEvaluator(\n",
    "        training_data={\"xor\": \"xor_train.csv\",\n",
    "                       \"center_surround\": \"center_surround_train.csv\",\n",
    "                       \"spiral\": \"spiral_train.csv\",\n",
    "                       \"two_gaussians\": \"two_gaussians_train.csv\"\n",
    "                       },\n",
    "        test_data={\"xor\": \"xor_test.csv\",\n",
    "                   \"center_surround\": \"center_surround_test.csv\",\n",
    "                   \"spiral\": \"spiral_test.csv\",\n",
    "                   \"two_gaussians\": \"two_gaussians_test.csv\"\n",
    "                   },\n",
    "        validation_data={\"xor\": \"xor_valid.csv\",\n",
    "                         \"center_surround\": \"center_surround_valid.csv\",\n",
    "                         \"spiral\": \"spiral_valid.csv\",\n",
    "                         \"two_gaussians\": \"two_gaussians_valid.csv\"\n",
    "                         },\n",
    "        loss_functions={\"MCE\": nn.CrossEntropyLoss(), \"MSE\": nn.MSELoss()}\n",
    "    )\n",
    "    datasets = [\"xor\", \"center_surround\", \"spiral\", \"two_gaussians\"]\n",
    "    hidden_layer_sizes = [2, 3, 5, 7, 9]\n",
    "    losses = [\"MCE\", \"MSE\"]\n",
    "    regularizers = [\"\", \"norm\", \"orthogonal\"]\n",
    "    # After running and manually inspecting the results,\n",
    "    # these are the best HPs for each dataset and loss function\n",
    "    # These should also be used when using regularizers\n",
    "    best_hps_map = {\n",
    "        \"xor_MCE\": HyperParams(7, 0.01, \"MCE\"),\n",
    "        \"xor_MSE\": HyperParams(9, 0.01, \"MSE\"),\n",
    "        \"center_surround_MCE\": HyperParams(3, 0.01, \"MCE\"),\n",
    "        \"center_surround_MSE\": HyperParams(3, 0.01, \"MSE\"),\n",
    "        \"spiral_MCE\": HyperParams(9, 0.01, \"MCE\"),\n",
    "        \"spiral_MSE\": HyperParams(9, 0.01, \"MSE\"),\n",
    "        \"two_gaussians_MCE\": HyperParams(2, 0.01, \"MCE\"),\n",
    "        \"two_gaussians_MSE\": HyperParams(3, 0.01, \"MSE\")\n",
    "    }\n",
    "    for reg in regularizers:\n",
    "        for dataset in tqdm(datasets, desc=\"Datasets\"):\n",
    "            for loss in losses:\n",
    "                dataset_loss = f\"{dataset}_{loss}\"\n",
    "                hp = best_hps_map[dataset_loss]\n",
    "                evaluator.train_model(dataset, loss, reg, hp)\n",
    "        # Uncomment this block to train models with different hyperparams\n",
    "        # for dataset in tqdm(datasets, desc=\"Datasets\"):\n",
    "        #     for hl_size in hidden_layer_sizes:\n",
    "        #         for loss in losses:\n",
    "        #             hp = HyperParams(hl_size, 0.01, loss)\n",
    "        #             evaluator.train_model(dataset, loss, hp)\n",
    "        evaluator.print_evaluated_models()\n",
    "        for dataset in datasets:\n",
    "            for loss_name in losses:\n",
    "                best_hp, valid_acc, test_acc = evaluator.find_best_hyperparams_for_dataset(\n",
    "                    dataset, loss_name\n",
    "                )\n",
    "                print(\"======================================\")\n",
    "                print(f\"Best Hyperparams for {dataset}: {best_hp} Reg={reg}\")\n",
    "                print(f\"Validation Accuracy: {valid_acc}\")\n",
    "                print(f\"Test Accuracy: {test_acc}\")\n",
    "                print(\"======================================\\n\")\n",
    "                evaluator.plot_learning_curves(dataset, best_hp)\n",
    "                # evaluator.plot_learned_decision_surfaces(dataset, loss_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the evaluation\n",
    "evaluate_models_on_all_datasets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
